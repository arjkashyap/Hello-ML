{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import regularizers, applications\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow.keras import backend as k\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['Toddler', 'Teenagers', 'Adults']\n",
    "CLASSES = len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'data'\n",
    "train_path = os.path.join(PATH, 'train')\n",
    "IMG_SIZE=224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = 12        # Epochs\n",
    "bs = 32         # Batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('features.npy')\n",
    "y = np.load('labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2803, 224, 224, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255.0      # Normalize\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16 all frozen layers and Additional Conv layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"friendship-day-classifier-{}\".format(time.strftime(\"%d%h-%m-%S\"))\n",
    "tensorboard = TensorBoard(log_dir=\"\"\"logs\\{}\"\"\".format(NAME))\n",
    "\n",
    "def cnn_model(X_train, X_test , y_train, y_test):\n",
    "    \n",
    "    base_model = applications.VGG16(include_top=False, input_shape=X_train.shape[1:], weights='imagenet',classes=CLASSES)\n",
    "\n",
    "    # Freezing VGG16 layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable=False\n",
    "    \n",
    "    last_layer = 'block5_pool'\n",
    "    model = Model(base_model.input, base_model.get_layer(last_layer).output)\n",
    "\n",
    "    model.layers[-1].output.shape\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(base_model)      # Stack vgg16 \n",
    "\n",
    "    model.add(Conv2D(128,(3,3),activation=\"relu\", input_shape=model.layers[-1].output.shape, padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), padding='same'))\n",
    "    \n",
    "    model.add(Conv2D(64,(2,2),activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    \n",
    "    model.add(Flatten())        # Flatten the output\n",
    "\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(CLASSES, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=bs, epochs=ep, validation_data = (X_test, y_test), callbacks=[tensorboard])\n",
    "\n",
    "    # Save model\n",
    "    model.save(NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16, Last two layers unfrozen with 10 ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"vgg-unfreeze-last-2\"\n",
    "tensorboard = TensorBoard(log_dir=\"\"\"logs\\{}\"\"\".format(NAME))\n",
    "\n",
    "def cnn_model_3(X_train, X_test , y_train, y_test):\n",
    "    \n",
    "    base_model = applications.VGG16(include_top=False, input_shape=X_train.shape[1:], weights='imagenet',classes=CLASSES)\n",
    "\n",
    "    # Freezing VGG16 layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable=False\n",
    "    \n",
    "    # Unfreezing last two layers\n",
    "    base_model.layers[-1].trainable = True\n",
    "    base_model.layers[-2].trainable = True\n",
    "    \n",
    "    last_layer = 'block5_pool'\n",
    "    model = Model(base_model.input, base_model.get_layer(last_layer).output)\n",
    "\n",
    "    model.layers[-1].output.shape\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(base_model)      # Stack vgg16 \n",
    "\n",
    "#     model.add(Conv2D(128,(3,3),activation=\"relu\", input_shape=model.layers[-1].output.shape, padding='same'))\n",
    "#     model.add(MaxPooling2D(pool_size=(3, 3), padding='same'))\n",
    "    \n",
    "#     model.add(Conv2D(64,(2,2),activation=\"relu\"))\n",
    "#     model.add(MaxPooling2D(2,2))\n",
    "    \n",
    "    model.add(Flatten())        # Flatten the output\n",
    "\n",
    "    model.add(Dense(12, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(CLASSES, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=16, epochs=ep, validation_data = (X_test, y_test), callbacks=[tensorboard])\n",
    "\n",
    "    # Save model\n",
    "    model.save(NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"vgg-unfreeze-last-2-lr-ep20\"\n",
    "tensorboard = TensorBoard(log_dir=\"\"\"logs\\{}\"\"\".format(NAME))\n",
    "\n",
    "def cnn_model_3(X_train, X_test , y_train, y_test):\n",
    "    \n",
    "    base_model = applications.VGG16(include_top=False, input_shape=X_train.shape[1:], weights='imagenet',classes=CLASSES)\n",
    "\n",
    "    # Freezing VGG16 layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable=False\n",
    "    \n",
    "    # Unfreezing last two layers\n",
    "    base_model.layers[-1].trainable = True\n",
    "    base_model.layers[-2].trainable = True\n",
    "    \n",
    "    last_layer = 'block5_pool'\n",
    "    model = Model(base_model.input, base_model.get_layer(last_layer).output)\n",
    "\n",
    "    model.layers[-1].output.shape\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(base_model)      # Stack vgg16 \n",
    "\n",
    "#     model.add(Conv2D(128,(3,3),activation=\"relu\", input_shape=model.layers[-1].output.shape, padding='same'))\n",
    "#     model.add(MaxPooling2D(pool_size=(3, 3), padding='same'))\n",
    "    \n",
    "#     model.add(Conv2D(64,(2,2),activation=\"relu\"))\n",
    "#     model.add(MaxPooling2D(2,2))\n",
    "    \n",
    "    model.add(Flatten())        # Flatten the output\n",
    "\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(CLASSES, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001) , loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=bs, epochs=ep, validation_data = (X_test, y_test), callbacks=[tensorboard])\n",
    "\n",
    "    # Save model\n",
    "    model.save(NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2242 samples, validate on 561 samples\n",
      "Epoch 1/20\n",
      "2242/2242 [==============================] - 94s 42ms/sample - loss: 3.0244 - accuracy: 0.4670 - val_loss: 2.4724 - val_accuracy: 0.5775\n",
      "Epoch 2/20\n",
      "2242/2242 [==============================] - 76s 34ms/sample - loss: 2.1037 - accuracy: 0.6494 - val_loss: 1.9735 - val_accuracy: 0.6078\n",
      "Epoch 3/20\n",
      "2242/2242 [==============================] - 81s 36ms/sample - loss: 1.6912 - accuracy: 0.7132 - val_loss: 1.7245 - val_accuracy: 0.6364\n",
      "Epoch 4/20\n",
      "2242/2242 [==============================] - 84s 37ms/sample - loss: 1.3919 - accuracy: 0.8033 - val_loss: 1.5610 - val_accuracy: 0.6631\n",
      "Epoch 5/20\n",
      "2242/2242 [==============================] - 84s 37ms/sample - loss: 1.1511 - accuracy: 0.8680 - val_loss: 1.5499 - val_accuracy: 0.6524\n",
      "Epoch 6/20\n",
      "2242/2242 [==============================] - 84s 37ms/sample - loss: 0.9687 - accuracy: 0.9193 - val_loss: 1.4315 - val_accuracy: 0.6791\n",
      "Epoch 7/20\n",
      "2242/2242 [==============================] - 83s 37ms/sample - loss: 0.8520 - accuracy: 0.9349 - val_loss: 1.4334 - val_accuracy: 0.6684\n",
      "Epoch 8/20\n",
      "2242/2242 [==============================] - 83s 37ms/sample - loss: 0.7514 - accuracy: 0.9572 - val_loss: 1.3993 - val_accuracy: 0.6791\n",
      "Epoch 9/20\n",
      "2242/2242 [==============================] - 84s 37ms/sample - loss: 0.6406 - accuracy: 0.9759 - val_loss: 1.4326 - val_accuracy: 0.6774\n",
      "Epoch 10/20\n",
      "2242/2242 [==============================] - 83s 37ms/sample - loss: 0.5894 - accuracy: 0.9755 - val_loss: 1.3601 - val_accuracy: 0.6952\n",
      "Epoch 11/20\n",
      "2242/2242 [==============================] - 83s 37ms/sample - loss: 0.5305 - accuracy: 0.9871 - val_loss: 1.3488 - val_accuracy: 0.6774\n",
      "Epoch 12/20\n",
      "2242/2242 [==============================] - 84s 37ms/sample - loss: 0.4883 - accuracy: 0.9871 - val_loss: 1.3316 - val_accuracy: 0.6774\n",
      "Epoch 13/20\n",
      "2242/2242 [==============================] - 84s 37ms/sample - loss: 0.4410 - accuracy: 0.9902 - val_loss: 1.3112 - val_accuracy: 0.6791\n",
      "Epoch 14/20\n",
      "2242/2242 [==============================] - 83s 37ms/sample - loss: 0.4050 - accuracy: 0.9906 - val_loss: 1.3344 - val_accuracy: 0.6934\n",
      "Epoch 15/20\n",
      "2242/2242 [==============================] - 83s 37ms/sample - loss: 0.3734 - accuracy: 0.9897 - val_loss: 1.3042 - val_accuracy: 0.6809\n",
      "Epoch 16/20\n",
      "2242/2242 [==============================] - 84s 37ms/sample - loss: 0.3519 - accuracy: 0.9888 - val_loss: 1.3252 - val_accuracy: 0.6827\n",
      "Epoch 17/20\n",
      "2242/2242 [==============================] - 83s 37ms/sample - loss: 0.3219 - accuracy: 0.9915 - val_loss: 1.2930 - val_accuracy: 0.6595\n",
      "Epoch 18/20\n",
      "2242/2242 [==============================] - 83s 37ms/sample - loss: 0.2982 - accuracy: 0.9929 - val_loss: 1.2088 - val_accuracy: 0.6863\n",
      "Epoch 19/20\n",
      "2242/2242 [==============================] - 83s 37ms/sample - loss: 0.2690 - accuracy: 0.9951 - val_loss: 1.2234 - val_accuracy: 0.6952\n",
      "Epoch 20/20\n",
      "2242/2242 [==============================] - 83s 37ms/sample - loss: 0.2525 - accuracy: 0.9933 - val_loss: 1.2594 - val_accuracy: 0.6809\n",
      "WARNING:tensorflow:From c:\\users\\asus\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: vgg-unfreeze-last-2-lr-ep20\\assets\n"
     ]
    }
   ],
   "source": [
    "#cnn_model_3(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16 with last two unfrozen layers and Dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME=\"frozen_vgg\"\n",
    "checkpoint_path = \"saved_weights/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "def frozen_vgg(X_train, X_test , y_train, y_test):\n",
    "    \n",
    "    base_model = applications.VGG16(include_top=False, input_shape=X_train.shape[1:], weights='imagenet',classes=CLASSES)\n",
    "\n",
    "    # Freezing VGG16 layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable=False\n",
    "    \n",
    "    base_model.layers[-1].trainable = True\n",
    "    base_model.layers[-2].trainable = True\n",
    "    \n",
    "    last_layer = 'block5_pool'\n",
    "    model = Model(base_model.input, base_model.get_layer(last_layer).output)\n",
    "\n",
    "    model.layers[-1].output.shape\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(base_model)      # Stack vgg16 \n",
    "\n",
    "\n",
    "    \n",
    "    model.add(Flatten())        # Flatten the output\n",
    "\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(CLASSES, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=bs, epochs=ep, validation_data = (X_test, y_test), callbacks=[cp_callback])\n",
    "\n",
    "    # Save model\n",
    "    model.save(NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2242 samples, validate on 561 samples\n",
      "Epoch 1/12\n",
      "2240/2242 [============================>.] - ETA: 0s - loss: 2.1058 - accuracy: 0.4897\n",
      "Epoch 00001: saving model to saved_weights/cp.ckpt\n",
      "2242/2242 [==============================] - 98s 44ms/sample - loss: 2.1048 - accuracy: 0.4897 - val_loss: 1.3843 - val_accuracy: 0.5597\n",
      "Epoch 2/12\n",
      "2240/2242 [============================>.] - ETA: 0s - loss: 1.0993 - accuracy: 0.6415\n",
      "Epoch 00002: saving model to saved_weights/cp.ckpt\n",
      "2242/2242 [==============================] - 80s 36ms/sample - loss: 1.0993 - accuracy: 0.6414 - val_loss: 1.1324 - val_accuracy: 0.5704\n",
      "Epoch 3/12\n",
      "2240/2242 [============================>.] - ETA: 0s - loss: 0.8739 - accuracy: 0.7116\n",
      "Epoch 00003: saving model to saved_weights/cp.ckpt\n",
      "2242/2242 [==============================] - 80s 36ms/sample - loss: 0.8736 - accuracy: 0.7119 - val_loss: 1.0391 - val_accuracy: 0.6346\n",
      "Epoch 4/12\n",
      "2240/2242 [============================>.] - ETA: 0s - loss: 0.7172 - accuracy: 0.7906\n",
      "Epoch 00004: saving model to saved_weights/cp.ckpt\n",
      "2242/2242 [==============================] - 80s 36ms/sample - loss: 0.7175 - accuracy: 0.7904 - val_loss: 1.1788 - val_accuracy: 0.6150\n",
      "Epoch 5/12\n",
      "2240/2242 [============================>.] - ETA: 0s - loss: 0.6398 - accuracy: 0.8317\n",
      "Epoch 00005: saving model to saved_weights/cp.ckpt\n",
      "2242/2242 [==============================] - 79s 35ms/sample - loss: 0.6397 - accuracy: 0.8318 - val_loss: 1.1783 - val_accuracy: 0.6364\n",
      "Epoch 6/12\n",
      "2240/2242 [============================>.] - ETA: 0s - loss: 0.5101 - accuracy: 0.8938\n",
      "Epoch 00006: saving model to saved_weights/cp.ckpt\n",
      "2242/2242 [==============================] - 79s 35ms/sample - loss: 0.5100 - accuracy: 0.8938 - val_loss: 1.3683 - val_accuracy: 0.6542\n",
      "Epoch 7/12\n",
      "2240/2242 [============================>.] - ETA: 0s - loss: 0.4197 - accuracy: 0.9246\n",
      "Epoch 00007: saving model to saved_weights/cp.ckpt\n",
      "2242/2242 [==============================] - 79s 35ms/sample - loss: 0.4198 - accuracy: 0.9246 - val_loss: 1.4630 - val_accuracy: 0.6043\n",
      "Epoch 8/12\n",
      "2240/2242 [============================>.] - ETA: 0s - loss: 0.3506 - accuracy: 0.9509\n",
      "Epoch 00008: saving model to saved_weights/cp.ckpt\n",
      "2242/2242 [==============================] - 79s 35ms/sample - loss: 0.3505 - accuracy: 0.9509 - val_loss: 1.4531 - val_accuracy: 0.6114\n",
      "Epoch 9/12\n",
      "2240/2242 [============================>.] - ETA: 0s - loss: 0.2826 - accuracy: 0.9710\n",
      "Epoch 00009: saving model to saved_weights/cp.ckpt\n",
      "2242/2242 [==============================] - 79s 35ms/sample - loss: 0.2825 - accuracy: 0.9710 - val_loss: 1.6535 - val_accuracy: 0.6275\n",
      "Epoch 10/12\n",
      "2240/2242 [============================>.] - ETA: 0s - loss: 0.2642 - accuracy: 0.9732\n",
      "Epoch 00010: saving model to saved_weights/cp.ckpt\n",
      "2242/2242 [==============================] - 79s 35ms/sample - loss: 0.2641 - accuracy: 0.9732 - val_loss: 1.5528 - val_accuracy: 0.6524\n",
      "Epoch 11/12\n",
      "2240/2242 [============================>.] - ETA: 0s - loss: 0.2088 - accuracy: 0.9857\n",
      "Epoch 00011: saving model to saved_weights/cp.ckpt\n",
      "2242/2242 [==============================] - 79s 35ms/sample - loss: 0.2087 - accuracy: 0.9857 - val_loss: 1.6328 - val_accuracy: 0.6453\n",
      "Epoch 12/12\n",
      "2240/2242 [============================>.] - ETA: 0s - loss: 0.1728 - accuracy: 0.9897\n",
      "Epoch 00012: saving model to saved_weights/cp.ckpt\n",
      "2242/2242 [==============================] - 79s 35ms/sample - loss: 0.1727 - accuracy: 0.9897 - val_loss: 1.6074 - val_accuracy: 0.6203\n",
      "WARNING:tensorflow:From c:\\users\\asus\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: frozen_vgg\\assets\n"
     ]
    }
   ],
   "source": [
    "frozen_vgg(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME=\"ftp-ep10\"\n",
    "def ftp(X_train, X_test , y_train, y_test):\n",
    "    base_model = applications.VGG16(include_top=False, input_shape=X_train.shape[1:], weights=None,classes=CLASSES)\n",
    "\n",
    "    # Freezing VGG16 layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable=False\n",
    "    \n",
    "    base_model.layers[-1].trainable = True\n",
    "    base_model.layers[-2].trainable = True\n",
    "    \n",
    "    last_layer = 'block5_pool'\n",
    "    model = Model(base_model.input, base_model.get_layer(last_layer).output)\n",
    "\n",
    "    model.layers[-1].output.shape\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(base_model)      # Stack vgg16 \n",
    "\n",
    "    \n",
    "    model.add(Flatten())        # Flatten the output\n",
    "\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(CLASSES, activation=\"softmax\"))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001) , loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.load_weights(checkpoint_path)\n",
    "    model.fit(X_train, y_train, batch_size=bs, epochs=ep, validation_data = (X_test, y_test))\n",
    "\n",
    "    # Save model\n",
    "    model.save(NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2242 samples, validate on 561 samples\n",
      "Epoch 1/12\n",
      "2242/2242 [==============================] - 82s 36ms/sample - loss: 0.1539 - accuracy: 0.9920 - val_loss: 1.7895 - val_accuracy: 0.6185\n",
      "Epoch 2/12\n",
      "2242/2242 [==============================] - 78s 35ms/sample - loss: 0.1448 - accuracy: 0.9924 - val_loss: 1.5548 - val_accuracy: 0.6435\n",
      "Epoch 3/12\n",
      "2242/2242 [==============================] - 78s 35ms/sample - loss: 0.1295 - accuracy: 0.9920 - val_loss: 1.5364 - val_accuracy: 0.6399\n",
      "Epoch 4/12\n",
      "2242/2242 [==============================] - 81s 36ms/sample - loss: 0.1459 - accuracy: 0.9884 - val_loss: 1.6025 - val_accuracy: 0.6061\n",
      "Epoch 5/12\n",
      "2242/2242 [==============================] - 78s 35ms/sample - loss: 0.1623 - accuracy: 0.9888 - val_loss: 2.0215 - val_accuracy: 0.6542\n",
      "Epoch 6/12\n",
      "2242/2242 [==============================] - 78s 35ms/sample - loss: 0.1672 - accuracy: 0.9839 - val_loss: 1.7707 - val_accuracy: 0.6168\n",
      "Epoch 7/12\n",
      "2242/2242 [==============================] - 79s 35ms/sample - loss: 0.1456 - accuracy: 0.9893 - val_loss: 1.7198 - val_accuracy: 0.6435\n",
      "Epoch 8/12\n",
      "2242/2242 [==============================] - 78s 35ms/sample - loss: 0.1741 - accuracy: 0.9826 - val_loss: 1.8486 - val_accuracy: 0.6221\n",
      "Epoch 9/12\n",
      "2242/2242 [==============================] - 78s 35ms/sample - loss: 0.1950 - accuracy: 0.9822 - val_loss: 1.7497 - val_accuracy: 0.6132\n",
      "Epoch 10/12\n",
      "2242/2242 [==============================] - 78s 35ms/sample - loss: 0.1596 - accuracy: 0.9897 - val_loss: 1.8909 - val_accuracy: 0.6043\n",
      "Epoch 11/12\n",
      "2242/2242 [==============================] - 79s 35ms/sample - loss: 0.1742 - accuracy: 0.9866 - val_loss: 1.8254 - val_accuracy: 0.6364\n",
      "Epoch 12/12\n",
      "2242/2242 [==============================] - 78s 35ms/sample - loss: 0.1308 - accuracy: 0.9951 - val_loss: 1.8387 - val_accuracy: 0.6328\n",
      "INFO:tensorflow:Assets written to: ftp-ep10\\assets\n"
     ]
    }
   ],
   "source": [
    "model = ftp(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv = \"./data/test.csv\"        # Path to test.csv file\n",
    "test_images = \"./data/test/\"        # Path to test images folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./ftp-model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(314, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "def create_test_data():\n",
    "    images = []       # List containes path of all the testing images in right seq\n",
    "    test_data = []    \n",
    "    df = pd.read_csv(test_csv)\n",
    "    names_df = df['Filename']\n",
    "    for img in names_df:\n",
    "        img_path = os.path.join(test_images, img)\n",
    "        images.append(img_path)        \n",
    "    for img_path in images:\n",
    "        try:\n",
    "            img_array = cv2.imread(img_path ,cv2.COLOR_BGR2RGB)  # convert to array\n",
    "            img_array = img_array/255.0\n",
    "            new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "            test_data.append(new_array.reshape(IMG_SIZE, IMG_SIZE, 3))  # add this to our training_data\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error !!\")\n",
    "            print(e)\n",
    "            pass\n",
    "    return test_data\n",
    "\n",
    "    \n",
    "test_data = np.array(create_test_data())\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 1, 1, 1]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for i in prediction:\n",
    "    results.append(np.argmax(i))\n",
    "    \n",
    "results[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(results):\n",
    "    images = pd.read_csv(test_csv)['Filename']\n",
    "    with open('ftp-model.csv', 'w', newline='') as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"Filename\", \"Category\"])\n",
    "        for i in range(len(images)):\n",
    "            res = str(categories[results[i]])\n",
    "            img = images[i]\n",
    "            w.writerow([img, res])\n",
    "            \n",
    "save_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
